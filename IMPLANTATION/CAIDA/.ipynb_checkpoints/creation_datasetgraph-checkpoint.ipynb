{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77fbc303",
   "metadata": {},
   "source": [
    "## Script de création de graphe\n",
    "cf base de donnée CAIDA : https://publicdata.caida.org/datasets/as-relationships/serial-2/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9b3bec",
   "metadata": {},
   "source": [
    "**README :**\n",
    " \n",
    "The as-rel file contain p2p and p2c relationships.\n",
    "The format is:\n",
    "\n",
    "`<provider-as>|<customer-as>|-1` <br>\n",
    "`<peer-as>|<peer-as>|0|<source>`\n",
    "\n",
    "    \n",
    "Example : \n",
    "    \n",
    "`1|11537|0|bgp` <br>\n",
    "`1|21616|-1|bgp`\n",
    "\n",
    "Le fichier contient environ 100 000 lignes de ce type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3b4efe8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m     11\u001b[0m os\u001b[38;5;241m.\u001b[39mpopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexport DGLBACKEND=pytorch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdgl\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdgl\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preprocessing\n",
      "File \u001b[1;32mC:\\Python39\\lib\\site-packages\\dgl\\__init__.py:13\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msocket\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Should import backend before importing anything else\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_backend, backend_name\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m function\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m contrib\n",
      "File \u001b[1;32mC:\\Python39\\lib\\site-packages\\dgl\\backend\\__init__.py:107\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    103\u001b[0m         set_default_backend(default_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 107\u001b[0m \u001b[43mload_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_preferred_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_enabled\u001b[39m(api):\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;124;03m\"\"\"Return true if the api is enabled by the current backend.\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03m        True if the API is enabled by the current backend.\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python39\\lib\\site-packages\\dgl\\backend\\__init__.py:30\u001b[0m, in \u001b[0;36mload_backend\u001b[1;34m(mod_name)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_backend\u001b[39m(mod_name):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Load backend does four things:\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# (1) Import backend framework (PyTorch, MXNet, Tensorflow, etc.)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# (4) Import the Python wrappers of the backend framework.  DGL does this last because\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m#     it already depends on both the backend framework and the DGL C library.\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mod_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 30\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     31\u001b[0m         mod \u001b[38;5;241m=\u001b[39m torch\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mod_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmxnet\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mC:\\Python39\\lib\\site-packages\\torch\\__init__.py:229\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(textwrap\u001b[38;5;241m.\u001b[39mdedent(\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;124m            Failed to load PyTorch C extensions:\u001b[39m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124m                It appears that PyTorch has loaded the `torch/_C` folder\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;124m                or by running Python from a different directory.\u001b[39m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124m            \u001b[39m\u001b[38;5;124m'''\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m  \u001b[38;5;66;03m# If __file__ is not None the cause is unknown, so just re-raise.\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m __all__ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [name \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(\u001b[43m_C\u001b[49m)\n\u001b[0;32m    230\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m name[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    231\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBase\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# issue 38137 and python issue 43367. Submodules of a C extension are\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# non-standard, and attributes of those submodules cannot be pickled since\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;66;03m# pickle expect to be able to import them as \"from _C.sub import attr\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;66;03m# which fails with \"_C is not a package\u001b[39;00m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(_C):\n",
      "\u001b[1;31mNameError\u001b[0m: name '_C' is not defined"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import pickle\n",
    "os.popen(\"export DGLBACKEND=pytorch\")\n",
    "import dgl as dgl\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import arange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdc80c9",
   "metadata": {},
   "source": [
    "#### Définition diverses de fonction (utilisant du bash) permettant de vérifier que le graphe a été bien créé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc75423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fichier au choix parmi ceux de ./data/CAIDA_AS_RELATIONSHIP\n",
    "\n",
    "#FILE_PATH='./data/CAIDA_AS_RELATIONSHIP/20200101.as-rel2.txt'\n",
    "FILE_PATH='./data/CAIDA_AS_RELATIONSHIP/20210301.as-rel2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0487284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encadre(message):\n",
    "    print(\"\\n****************************\")\n",
    "    print(message)\n",
    "    print(\"****************************\\n\")\n",
    "\n",
    "def nb_nodes_of_file(file):\n",
    "    return int(os.popen(\"cat %s | grep \\\"^[0-9][0-9]*\\\" | awk -F \\\"|\\\" '{ print $1 \\\"\\\\n\\\" $2 }' | sort -h | uniq | wc -l\" %file).read())\n",
    "    \n",
    "#def nb_edges_of_file(file):\n",
    "#    return os.popen(\"cat %s | grep \\\"^[0-9][0-9]*\\\" | awk -F \\\"|\\\" '{ print $1 \\\"\\\\n\\\" $2 }' | sort -h | uniq | wc -l\" %file).read()\n",
    "\n",
    "def list_nodes_sorted(file):\n",
    "    return os.popen(\"cat %s | grep \\\"^[0-9][0-9]*\\\" | awk -F \\\"|\\\" '{ print $1 \\\"\\\\n\\\" $2 }' | sort -h | uniq\" %file).read()\n",
    "\n",
    "def nb_peering_customer_provider(ASN):\n",
    "    nb_peerings =  os.popen(\"cat %s | grep \\\"^%s|\\||%s|\\\" | grep -v \\\".*\\-1\\\" | wc -l\" % (FILE_PATH, ASN, ASN)).read()\n",
    "    nb_customers = os.popen(\"cat %s | grep \\\"^%s|.*\\-1\\\" |wc -l \" % (FILE_PATH, ASN)).read()\n",
    "    nb_providers = os.popen(\"cat %s | grep \\\"|%s|\\-1\\\" | wc -l\" % (FILE_PATH, ASN)).read()\n",
    "    return nb_peerings.split(\"\\n\")[0], nb_customers.split(\"\\n\")[0], nb_providers.split(\"\\n\")[0]\n",
    "\n",
    "def csv_dataset(file):\n",
    "    return os.popen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519e52f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_nodes_file = nb_nodes_of_file(FILE_PATH)\n",
    "print(\"Nb nodes of file : \" + str(nb_nodes_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eb1083",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_type_links = nb_peering_customer_provider(4)\n",
    "print(\"Link types and number (p2p, c, p) of node index 4 : \" + str(nb_type_links))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cece85",
   "metadata": {},
   "source": [
    "### Panda Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b1b53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AS_dataset_202001 = pd.read_csv('data/CAIDA_AS_CLASSIFICATION/20200101.as2types.txt', sep='|')\n",
    "AS_dataset = pd.read_csv('data/CAIDA_AS_CLASSIFICATION/20210301.as2types.txt', sep='|')\n",
    "\n",
    "### ATTENTION : si erreur, lancer le script `./sort_datasets.sh -h`\n",
    "\n",
    "# Vérif nombre de noeuds\n",
    "assert (len(AS_dataset.index) == nb_nodes_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88332e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f70de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(AS_dataset[\"label\"].value_counts())\n",
    "print(\"\\n\")\n",
    "print(AS_dataset[\"source_label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2bbd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset[\"label\"].value_counts(normalize=True).plot(kind='barh', grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb719c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d386056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictiongraph(fichier_texte):\n",
    "    fichier = open(fichier_texte,\"r\")\n",
    "    dictio = []\n",
    "    memoire=-1\n",
    "    for ligne in fichier:\n",
    "        tabligne = ligne.split(\"|\")\n",
    "        try:\n",
    "            asn1 = int(tabligne[0])\n",
    "            asn2 = int(tabligne[1])\n",
    "            if asn1 != memoire:\n",
    "                dictio.append(asn1)\n",
    "                memoire = asn1\n",
    "            dictio.append(asn2)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    l = arange(len(list(set(dictio))))\n",
    "    dictiofinal =dict_from_list = dict(zip(sorted(list(set(dictio))), l))\n",
    "    return dictiofinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b51058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creation_graph(fichier_texte):\n",
    "    G = nx.Graph() \n",
    "    fichier = open(fichier_texte,\"r\")\n",
    "    cpt = 0\n",
    "    memoire = -1\n",
    "    dictio = dictiongraph(fichier_texte)\n",
    "    i=0\n",
    "    #Ajout de tous les noeuds\n",
    "    for num_as in dictio :\n",
    "        G.add_node(i,asn=num_as)\n",
    "        i+=1\n",
    "    #Ajout des arêtes\n",
    "    for ligne in fichier:\n",
    "        tabligne = ligne.split(\"|\")\n",
    "        try:\n",
    "            asn1 = int(tabligne[0])\n",
    "            asn2 = int(tabligne[1])\n",
    "            info = int(tabligne[2])\n",
    "            if info == 0 :\n",
    "                G.add_edge(dictio[asn1],dictio[asn2],type= str(asn1) + '|p2p|' +str(asn2))\n",
    "            elif info == -1 :\n",
    "                G.add_edge(dictio[asn1],dictio[asn2],type=str(asn1) + '|p2c|' +str(asn2))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eee71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = creation_graph(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeccbfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creation_graph_dirige(fichier_texte):\n",
    "    G = nx.DiGraph()\n",
    "    fichier = open(fichier_texte,\"r\")\n",
    "    cpt = 0\n",
    "    memoire = -1\n",
    "    dictio = dictiongraph(fichier_texte)\n",
    "    i=0\n",
    "    #Ajout de tous les noeuds\n",
    "    for num_as in dictio :\n",
    "        G.add_node(i,asn=num_as)\n",
    "        i+=1\n",
    "    #Ajout des arêtes\n",
    "    for ligne in fichier:\n",
    "        tabligne = ligne.split(\"|\")\n",
    "        try:\n",
    "            asn1 = int(tabligne[0])\n",
    "            asn2 = int(tabligne[1])\n",
    "            info = int(tabligne[2])\n",
    "            if info == 0 :\n",
    "                G.add_edge(dictio[asn1],dictio[asn2],type= 2/3)\n",
    "                G.add_edge(dictio[asn2],dictio[asn1],type= 2/3)\n",
    "            elif info == -1 :\n",
    "\n",
    "                G.add_edge(dictio[asn1],dictio[asn2],type= 3/3)\n",
    "                \n",
    "        except ValueError:\n",
    "            pass\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8216882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_directed = creation_graph_dirige(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43d8b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creation_graph_dirige_inverse(fichier_texte):\n",
    "    G = nx.DiGraph()\n",
    "    fichier = open(fichier_texte,\"r\")\n",
    "    cpt = 0\n",
    "    memoire = -1\n",
    "    dictio = dictiongraph(fichier_texte)\n",
    "    i=0\n",
    "    #Ajout de tous les noeuds\n",
    "    for num_as in dictio :\n",
    "        G.add_node(i,asn=num_as)\n",
    "        i+=1\n",
    "    #Ajout des arêtes\n",
    "    for ligne in fichier:\n",
    "        tabligne = ligne.split(\"|\")\n",
    "        try:\n",
    "            asn1 = int(tabligne[0])\n",
    "            asn2 = int(tabligne[1])\n",
    "            info = int(tabligne[2])\n",
    "            if info == 0 :\n",
    "                G.add_edge(dictio[asn1],dictio[asn2],type= 2/3)\n",
    "                G.add_edge(dictio[asn2],dictio[asn1],type= 2/3)\n",
    "            elif info == -1 :\n",
    "\n",
    "                G.add_edge(dictio[asn2],dictio[asn1],type= 3/3)\n",
    "                \n",
    "        except ValueError:\n",
    "            pass\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfa65ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_directed_inverse = creation_graph_dirige_inverse(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ae2471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_into_int(label):\n",
    "    if (label == 'Content'):\n",
    "        int_label = 0\n",
    "    elif (label == 'Transit/Access'):\n",
    "        int_label = 1\n",
    "    elif (label == 'Enterprise'):\n",
    "        int_label = 2\n",
    "    return int_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aeb026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creation_graph_float(fichier_texte):\n",
    "    G = nx.DiGraph()\n",
    "    fichier = open(fichier_texte,\"r\")\n",
    "    cpt = 0\n",
    "    memoire = -1\n",
    "    dictio = dictiongraph(fichier_texte)\n",
    "    i=0\n",
    "    #Ajout de tous les noeuds\n",
    "    for num_as in dictio :\n",
    "        G.add_node(i,label=label_into_int(AS_dataset['label'][i]))\n",
    "        #print(\"G add node : index \" + str(i) + \", asn : \" + str(num_as) + \", \" + AS_dataset['label'][i] + \" => \" + str(label_into_int(AS_dataset['label'][i])))\n",
    "        i+=1\n",
    "    #Ajout des arêtes\n",
    "    for ligne in fichier:\n",
    "        tabligne = ligne.split(\"|\")\n",
    "        try:\n",
    "            asn1 = int(tabligne[0])\n",
    "            asn2 = int(tabligne[1])\n",
    "            info = int(tabligne[2])\n",
    "            if info == 0 :\n",
    "                G.add_edge(dictio[asn1],dictio[asn2],type= 2/3)\n",
    "                G.add_edge(dictio[asn2],dictio[asn1],type= 2/3)\n",
    "            elif info == -1 :\n",
    "                G.add_edge(dictio[asn1],dictio[asn2],type= 3/3)\n",
    "                G.add_edge(dictio[asn2],dictio[asn1],type= 1/3)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "862513fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'creation_graph_float' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m G_float \u001b[38;5;241m=\u001b[39m\u001b[43mcreation_graph_float\u001b[49m(FILE_PATH)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'creation_graph_float' is not defined"
     ]
    }
   ],
   "source": [
    "G_float =creation_graph_float(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9ac9d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creation_graph_array(fichier_texte):\n",
    "    G = nx.DiGraph()\n",
    "    fichier = open(fichier_texte,\"r\")\n",
    "    cpt = 0\n",
    "    memoire = -1\n",
    "    dictio = dictiongraph(fichier_texte)\n",
    "    i=0\n",
    "    #Ajout de tous les noeuds\n",
    "    for num_as in dictio :\n",
    "        G.add_node(i,label=label_into_int(AS_dataset['label'][i]))\n",
    "        i+=1\n",
    "    #Ajout des arêtes\n",
    "    for ligne in fichier:\n",
    "        tabligne = ligne.split(\"|\")\n",
    "        try:\n",
    "            asn1 = int(tabligne[0])\n",
    "            asn2 = int(tabligne[1])\n",
    "            info = int(tabligne[2])\n",
    "            if info == 0 :\n",
    "                G.add_edge(dictio[asn1],dictio[asn2],type= np.array([0,1,0]))\n",
    "                G.add_edge(dictio[asn2],dictio[asn1],type= np.array([0,1,0]))\n",
    "            elif info == -1 :\n",
    "                G.add_edge(dictio[asn1],dictio[asn2],type=np.array([1,0,0]))\n",
    "                G.add_edge(dictio[asn2],dictio[asn1],type=np.array([0,0,1]))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "883d7def",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FILE_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m G_array\u001b[38;5;241m=\u001b[39mcreation_graph_array(\u001b[43mFILE_PATH\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'FILE_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "G_array=creation_graph_array(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9ab4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_nodes_graph = G.number_of_nodes()\n",
    "nb_edges_graph = G.number_of_edges()\n",
    "\n",
    "print(\"Nb nodes du graphe : \" + str(nb_nodes_graph))\n",
    "print(\"Nb edges du graphe: \" + str(nb_edges_graph))\n",
    "\n",
    "assert(nb_nodes_graph == int(nb_nodes_of_file(FILE_PATH)))\n",
    "print(\"\\nASSERT NB NODES OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee183443",
   "metadata": {},
   "source": [
    "- ### Ajout des colonnes `page_rank_not_directed`, `page_rank_directed` et `degree_centrality`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354ef3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pageRank = nx.pagerank(G).values()\n",
    "list_pageRank_directed = nx.pagerank(G_directed).values()\n",
    "list_pageRank_directed_inverse = nx.pagerank(G_directed_inverse).values()\n",
    "list_degreeCentrality = nx.degree_centrality(G).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039ce0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset['page_rank_not_directed'] = list_pageRank\n",
    "AS_dataset['page_rank_directed'] = list_pageRank_directed\n",
    "AS_dataset['page_rank_directed_inverse'] = list_pageRank_directed_inverse\n",
    "AS_dataset['degree_centrality'] = list_degreeCentrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4966dfe3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "AS_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1b8264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictiongraph_Nbnoeud_Asn(fichier_texte):\n",
    "    fichier = open(fichier_texte,\"r\")\n",
    "    dictio = []\n",
    "    memoire=-1\n",
    "    for ligne in fichier:\n",
    "        tabligne = ligne.split(\"|\")\n",
    "        try:\n",
    "            asn1 = int(tabligne[0])\n",
    "            asn2 = int(tabligne[1])\n",
    "            if asn1 != memoire:\n",
    "                dictio.append(asn1)\n",
    "                memoire = asn1\n",
    "            dictio.append(asn2)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    l = arange(len(list(set(dictio))))\n",
    "    dictiofinal =dict_from_list = dict(zip(l, sorted(list(set(dictio)))))\n",
    "    return dictiofinal\n",
    "Dictio_noeud_as = dictiongraph_Nbnoeud_Asn(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6479bce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nbtypevoisins2(G):\n",
    "    nbNoeuds = G.number_of_nodes()\n",
    "    Liste_Nb_Voisins_Peering = np.zeros(nbNoeuds)\n",
    "    Liste_Nb_Voisins_Customer = np.zeros(nbNoeuds)\n",
    "    Liste_Nb_Voisins_Provider = np.zeros(nbNoeuds)\n",
    "    for i in range(nbNoeuds):\n",
    "        for j in range(len(G[i])) :\n",
    "            infos = list(G[i].values())[j][\"type\"].split(\"|\")\n",
    "            #print(infos)\n",
    "            type_lien = infos[1]\n",
    "            if type_lien == \"p2p\":\n",
    "\n",
    "                Liste_Nb_Voisins_Peering[i] +=1\n",
    "                #Liste_Nb_Voisins_Peering[dictio_as_noeud[int(asn2)]] +=1\n",
    "            elif type_lien == \"p2c\":\n",
    "                asn1 = infos[0]\n",
    "                asn2 = infos[2]\n",
    "                if int(asn2) == int(Dictio_noeud_as[i]) :\n",
    "                     Liste_Nb_Voisins_Provider[i]+=1                \n",
    "                else :\n",
    "                    Liste_Nb_Voisins_Customer[i]+=1\n",
    "\n",
    "        #print(i)\n",
    "\n",
    "    return Liste_Nb_Voisins_Peering, Liste_Nb_Voisins_Customer, Liste_Nb_Voisins_Provider \n",
    "                \n",
    "#### TEMPS D'EXECUTION : 5min ~\n",
    "L1,L2,L3=nbtypevoisins2(G) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863911ef",
   "metadata": {},
   "source": [
    "- ### Vérification de la conformité des listes L1, L2 et L3 par rapport au graphe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7841246f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_degree_list = max(L1 + L2 + L3)\n",
    "highest_degree_graph = max(list(dict(G.degree()).values()))\n",
    "index_max = list(dict(G.degree()).values()).index(highest_degree_graph)\n",
    "ASN_max = list(Dictio_noeud_as.values())[index_max]\n",
    "\n",
    "print(\"Max degree list : \" + str(max_degree_list))\n",
    "print(\"Max degree index : \" + str(index_max) + \", max degree ASN : \" + str(ASN_max))\n",
    "print(\"Max degree graph : \" + str(highest_degree_graph))\n",
    "\n",
    "assert (max_degree_list == highest_degree_graph)\n",
    "print(\"\\nASSERT MAX DEGREE OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ce6b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des maximum de p2p link, customer link et provider link\n",
    "max_p2p, index_max_p2p = np.max(L1), np.argmax(L1)\n",
    "max_c,   index_max_c   = np.max(L2), np.argmax(L2)\n",
    "max_p,   index_max_p   = np.max(L3), np.argmax(L3)\n",
    "\n",
    "print(\"Max p2p links          : \" + str(max_p2p) + \", index : \" + str(index_max_p2p) + \", ASN : \" + str(list(Dictio_noeud_as.values())[index_max_p2p]))\n",
    "print(\"Max nb customer links  : \" + str(max_c)   + \", index : \" + str(index_max_c)   + \", ASN : \" + str(list(Dictio_noeud_as.values())[index_max_c]))\n",
    "print(\"Max nb provider links  : \" + str(max_p)   + \", index : \" + str(index_max_p)   + \", ASN : \" + str(list(Dictio_noeud_as.values())[index_max_p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f2045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset.iloc[index_max_p2p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434c97f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset.iloc[index_max_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ccdfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset.iloc[index_max_p]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ab6ad5",
   "metadata": {},
   "source": [
    "- ### Ajout de la colonne `degree_normalized` définit par la valeur centrée-réduite du degré de chaque noeud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a392f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "List_degree = L1 + L2 + L3\n",
    "\n",
    "AS_dataset['degree_normalized'] = sklearn.preprocessing.scale(List_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5035a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset['degree_normalized'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8010f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d2fb4f",
   "metadata": {},
   "source": [
    "- ### Ajout des colonnes `ratio_peering`, `ratio_customer` et `ratio_provider`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cf828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset['ratio_peering']  = L1 / List_degree\n",
    "AS_dataset['ratio_customer'] = L2 / List_degree\n",
    "AS_dataset['ratio_provider'] = L3 / List_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb6e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6240350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset['ratio_peering'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d490d95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset['ratio_customer'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac24e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset['ratio_provider'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafb1591",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a1e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset [AS_dataset['ASN'] == 6939]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d115d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_max_p2p = AS_dataset.index [AS_dataset['ASN'] == 6939]\n",
    "print(\"Nb p2p : \" + str(int(L1[index_max_p2p]))\n",
    "      + \"\\nNb c   : \" + str(int(L2[index_max_p2p])) \n",
    "      + \"\\nNb p   : \" + str(int(L3[index_max_p2p])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e64dd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AS_dataset['peering_links']  = L1\n",
    "#AS_dataset['customer_links'] = L2\n",
    "#AS_dataset['provider_links'] = L3\n",
    "\n",
    "#AS_dataset['peering_links_mal_scaled']    = AS_dataset['peering_links']/max_p2p\n",
    "#AS_dataset['customer_links_mal_scaled']   = AS_dataset['customer_links']/max_c\n",
    "#AS_dataset['provider_links_mal_scaled']   = AS_dataset['provider_links']/max_p\n",
    "\n",
    "#AS_dataset['peering_centre_reduit']  = sklearn.preprocessing.scale(AS_dataset['peering_links'])\n",
    "#AS_dataset['customer_centre_reduit'] = sklearn.preprocessing.scale(AS_dataset['customer_links'])\n",
    "#AS_dataset['provider_centre_reduit'] = sklearn.preprocessing.scale(AS_dataset['provider_links'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0001515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset['peering_links'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b40d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset['customer_links'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a5d6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset['provider_links'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02692dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset['peering_centre_reduit'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c964ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset['peering_centre_reduit'].quantile(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa72dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset['customer_centre_reduit'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf08416",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset['provider_centre_reduit'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649d6acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset['peering_links_mal_scaled'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739ce58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset['customer_links_mal_scaled'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ddca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset['provider_links_mal_scaled'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4d6d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset['peering_links_mal_scaled'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e33d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset['customer_links'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53313405",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset['provider_links'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f654d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset['peering_links'] = L1/max_p2p\n",
    "AS_dataset['customer_links'] = L2/max_c\n",
    "AS_dataset['provider_links'] = L3/max_p\n",
    "\n",
    "assert(AS_dataset['peering_links'][index_max_p2p] == 1)\n",
    "assert(AS_dataset['customer_links'][index_max_c] == 1)\n",
    "assert(AS_dataset['provider_links'][index_max_p] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47067133",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e54f86",
   "metadata": {},
   "source": [
    "- ### Ajout des colonnes `is_Content`, `is_Transit` et `is_Enterprise`\n",
    "\n",
    "En effet, la colonne `label` est une **catégorie non ordinale**. Il faut donc la transformer en vecteur de valeur binaire, qui sera donné au GCN. <br> **On a alors :** <br><br>\n",
    "dataset['is_Content'][i] = 1 ⇔ le noeud i du graphe est de type `Content` <br>\n",
    "dataset['is_Transit'][i] = 1 ⇔ le noeud i du graphe est de type `Transit/Access` <br>\n",
    "dataset['is_Enterprise'][i] = 1 ⇔ le noeud i du graphe est de type `Enterprise` <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36554d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset['is_Content'] = (AS_dataset['label'] == 'Content').astype(int)\n",
    "AS_dataset['is_Transit'] = (AS_dataset['label'] == 'Transit/Access').astype(int)\n",
    "AS_dataset['is_Enterprise'] = (AS_dataset['label'] == 'Enterprise').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34133c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058f0df6",
   "metadata": {},
   "source": [
    "- ### Modification de la colonne `label`\n",
    "\n",
    "On transforme la **catégorie non ordinale** en 3 classes entières :\n",
    " - *Content* ⇔ $0$\n",
    " - *Transit/Access* ⇔ $1$\n",
    " - *Enterprise* ⇔ $2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f26c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset['label'] = AS_dataset['label'].map({'Content': 0, 'Transit/Access': 1, 'Enterprise': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d7460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaffd91",
   "metadata": {},
   "source": [
    "#### TO DO :\n",
    "- Afficher les n noeuds de plus haut degré du graphe G, avec les infos du ASN correspondant (en utilisant l'API de CAIDA)\n",
    "- Trouver d'autres visualisations de ce jeu de donnée qui le caractérisent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d747538e",
   "metadata": {},
   "source": [
    "### Exportation des données : `dataset` et `graph`\n",
    "\n",
    "On crée 4 fichiers : \n",
    "- Le `dataset`complet \n",
    "- Le `graphe` nx au format pickle\n",
    "- Le `graphe_float` nx au format pickle\n",
    "- Le `graphe_array` nx au format pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66dea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportation des données\n",
    "\n",
    "suffix = FILE_PATH.split('/')[3].split('.')[0]\n",
    "\n",
    "AS_dataset.to_csv('data_GCN/dataset_v2_'+suffix+'.csv', index=False)\n",
    "nx.write_gpickle(G, 'data_GCN/graph_'+suffix+'.pickle')\n",
    "nx.write_gpickle(G_float, 'data_GCN/graph_float_'+suffix+'.pickle')\n",
    "nx.write_gpickle(G_array, 'data_GCN/graph_array_'+suffix+'.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d916af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
